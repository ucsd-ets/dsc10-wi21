{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 7: Center, Spread, and Confidence Intervals\n",
    "\n",
    "## Due Saturday, March 6th at 11:59pm\n",
    "\n",
    "Welcome to Homework 7! This week, we will go over center, spread, and confidence intervals. You can find additional help on these topics in Lecture 19 (Bootstrapping), Lecture 20 (Confidence Intervals), and Lecture 21 (Center & Spread) of the course material. Please refer to [the course webpage](http://dsc10.com). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructions\n",
    "\n",
    "This assignment is due Saturday, March 6th at 11:59pm. You are given six slip days thoughout the quarter to extend deadlines. See the syllabus for more details. With the exception of using slip days, late work will not be accepted unless you have made special arrangements with your instructor.\n",
    "\n",
    "**Important**: The `otter` tests don't usually tell you that your answer is correct. More often, they help catch careless mistakes. It's up to you to ensure that your answer is correct. If you're not sure, ask someone (not for the answer, but for some guidance about your approach). Directly sharing answers is not okay, but discussing problems with the course staff or with other students is encouraged. \n",
    "\n",
    "Remember that you may work in pairs for this assignment! If you work in a pair, you must work with someone from your team, and you should submit one notebook to Gradescope for the both of you.\n",
    "\n",
    "You should start early so that you have time to get help if you're stuck. See the course calendar on Canvas for the schedule and Zoom links."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# please don't change this cell, but do make sure to run it\n",
    "import babypandas as bpd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import otter\n",
    "grader = otter.Notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Polling\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Four candidates are running for President of Dataland. A polling company surveys 1000 people selected uniformly at random from among voters in Dataland, and it asks each one who they are planning on voting for. After compiling the results, the polling company releases the following proportions from their sample:\n",
    "\n",
    "|Candidate  | Proportion|\n",
    "|:------------:|:------------:|\n",
    "|Candidate C | 0.55 |\n",
    "|Candidate T | 0.32 |\n",
    "|Candidate J | 0.08 |\n",
    "|Candidate S | 0.03 |\n",
    "|Undecided   | 0.02 |\n",
    "\n",
    "These proportions represent a uniform random sample of the population of Dataland. We will attempt to estimate the corresponding *population parameters* - the proportions of each kind of voter in the entire population.  We will use confidence intervals to compute a range of values that reflects the uncertainty of our estimate.\n",
    "\n",
    "The table `votes` contains the results of the survey. Candidates are represented by their initials. Undecided voters are denoted by `U`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#: run this cell to display the results of the survey -- don't change this cell!\n",
    "votes = bpd.DataFrame().assign(vote=np.array(['C']*550 + ['T']*320 + ['J']*80 + ['S']*30 + ['U']*20))\n",
    "votes = votes.sample(votes.shape[0],replace=False)\n",
    "num_votes = votes.shape[0]\n",
    "votes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we have given you code that will use bootstrapped samples to compute estimates of the true proportion of voters who are planning on voting for **Candidate C**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#: run the bootstrap\n",
    "def proportions_in_resamples():\n",
    "    statistics = np.array([])\n",
    "    for i in np.arange(1000):\n",
    "        bootstrap = votes.sample(num_votes, replace = True)\n",
    "        sample_statistic = np.count_nonzero(bootstrap.get('vote') == 'C')/num_votes\n",
    "        statistics = np.append(statistics, sample_statistic)\n",
    "    return statistics\n",
    "\n",
    "boot_proportions = proportions_in_resamples()\n",
    "bpd.DataFrame().assign(Estimated_Proportion=boot_proportions).plot(kind='hist',bins=np.arange(0.3,0.7,0.01))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.1.** Using the array `boot_proportions`, compute an approximate 95% confidence interval for the true proportion of voters planning on voting for candidate C.  (Compute the lower and upper ends of the interval, named `votes_lower_bound` and `votes_upper_bound`, respectively.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "votes_lower_bound = ...\n",
    "votes_upper_bound = ...\n",
    "\n",
    "#: print the confidence interval\n",
    "print(\"Bootstrapped 95% confidence interval for the proportion of C voters in the population: [{:f}, {:f}]\".format(votes_lower_bound, votes_upper_bound))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1_1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.2.** The survey results seem to indicate that Candidate C is beating Candidate T among voters. We would like to use confidence intervals to determine a range of likely values for her true *lead*. Candidate C's lead over Candidate T is:\n",
    "\n",
    "$$\\text{(Candidate C's proportion of the vote)} - \\text{(Candidate T's proportion of the vote)}.$$\n",
    "\n",
    "Use the bootstrap with 1000 resamples to compute an approximate distribution for Candidate C's lead over Candidate T, and store your bootstrap estimates in an array called `boot_leads`. Plot a histogram of the resulting samples.\n",
    "\n",
    "*Hint*: Use the code for `proportions_in_resamples` given to you above as a starting point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "for_assignment_type": "student",
    "manual_problem_id": "election_2"
   },
   "outputs": [],
   "source": [
    "def leads_in_resamples():\n",
    "    ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1_2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.3.** Compute an approximate 95% confidence interval for the difference in proportions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_lower_bound = ...\n",
    "diff_upper_bound = ...\n",
    "\n",
    "#: print the confidence interval\n",
    "print(\"Bootstrapped 95% confidence interval for Candidate C's true lead over Candidate T: [{:f}, {:f}]\".format(diff_lower_bound, diff_upper_bound))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1_3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The staff computed the following 95% confidence interval for the proportion of Candidate C voters: \n",
    "\n",
    "$$[.52, .58]$$\n",
    "\n",
    "(Your answer might have been slightly different, but that doesn't mean it was wrong since the data was randomly sampled.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.4.**\n",
    "Can we say that 95% of the population lies in the range $[.52, .58]$? Assign your choice to variable `q1_4`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Yes\n",
    "2. No"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1_4 = ...\n",
    "q1_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1_4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.5.**\n",
    "Can we say that the true proportion of the population that will vote for Candidate C is a random quantity with approximately a 95% chance of falling between 0.52 and 0.58? Assign your choice to variable `q1_5`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. No\n",
    "2. Yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1_5 = ...\n",
    "q1_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1_5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.6.**\n",
    "Suppose we produced 20,000 new samples (each one a uniform random sample of 1,000 voters) and created a 95% confidence interval from each one. Roughly how many of those 20,000 intervals do you expect will actually contain the true proportion of the population? Assign your answer to the variable `how_many` below. It should be the *number* of intervals, not the proportion or percentage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "how_many = ...\n",
    "how_many"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1_6\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.7.**\n",
    "\n",
    "The staff also created 80%, 90%, and 99% confidence intervals from one sample (shown below), but we forgot to label which confidence interval represented which percentages! Match the interval to the percent of confidence the interval represents and assign your choices in variables `q1_7_80`, `q1_7_90`, and `q1_7_99`, each for likely 80%, 90%, and 99% confidence intervals respectively.\n",
    "\n",
    "Tip: Draw out the confidence intervals on a piece a paper to help you visualize them better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. $[.516,.584]$\n",
    "\n",
    "2. $[.538,.563]$\n",
    "\n",
    "3. $[.53,.57]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1_7_80 = ...\n",
    "q1_7_90 = ...\n",
    "q1_7_99 = ...\n",
    "q1_7_80, q1_7_90, q1_7_99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1_7\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Hardest Writing Course\n",
    "Suppose it's application season and you're a current high school senior looking to apply to the prestigious UCSD for data science. Also, suppose you dislike writing and want to strategically analyze all the UCSD college writing courses, to figure out colleges to avoid applying to and colleges where you have the best shot at getting a decent grade. Luckily, UCSD has data on its CAPES website about writing courses (except for Muir's writing course due to unknown reasons). Each row corresponds to a particular quarter and course, and the data includes the name of the course, the average study hours per week for the quarter, and the average grade for the quarter (on a GPA scale). Now it's time to analyze and figure out whether the writing course rumors are true (or people just like complaining). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to read data; don't change it\n",
    "writing = bpd.read_csv(\"data/writing_courses_ucsd.csv\", index_col = 0)\n",
    "writing.iloc[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.1a.** The first thing to do before jumping into analysis is to figure out the mean study hours and mean grade for each course. Create a table called `course_means` that has index as `course` and columns consist of `Study Hrs/wk` and `grades`. `Study Hrs/wk` and `grades` contain the means of `Study Hrs/wk` and `grades` respectively. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "course_means = ...\n",
    "course_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2_1a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.1b.** You may have noticed that the mean grades for some courses is `nan`. This means that some grades are missing for these courses (missing values are represented by `nan`). Drop all the rows in the `writing` table that contain missing values and assign the new table to the variable `writing_fixed`. After this, create a table called `course_means_fixed` with no `nan` values in the `grades` column.\n",
    "\n",
    "Hint: [np.isnan()](https://docs.scipy.org/doc/numpy/reference/generated/numpy.isnan.html) or [np.isfinite()](https://docs.scipy.org/doc/numpy/reference/generated/numpy.isfinite.html) might be useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writing_fixed = ...\n",
    "course_means_fixed = ...\n",
    "writing_fixed, course_means_fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2_1b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.2.** Revelle's writing course HUM seems to have pretty low average grade. Produce 1,000 bootstrapped estimates for the average grade of HUM. Store the estimates in the `hum_averages` array. Use this `hum_averages` array to plot a histogram of the estimated averages. The label on the x-axis should be \"Estimated Average Grades for HUM\".\n",
    "\n",
    "Use the `hum_averages` array to calculate an approximate 95% confidence interval for the true average grade. Assign the the corresponding bounds to `lower_bound` and `upper_bound`. Do NOT round the bounds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hum_averages = ...\n",
    "\n",
    "lower_bound = ...\n",
    "upper_bound = ...\n",
    "lower_bound, upper_bound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2_2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.3.** You want to create a similar histogram for each of the other courses, and also calculate the corresponding confidence intervals. Repeating the process above 4 times would be time-consuming. Create a function called `ci_and_hist`, which takes in a course name as its input, plots the histogram for 1,000 bootstrapped estimates for the average grade and returns a `str` describing the approximate 95% confidence interval for the course (see the example below).\n",
    "\n",
    "For example, `ci_and_hist('HUM')` should plot the same histogram in Question 2 and return 'The 95% confidence interval for HUM is [2.85, 2.93]', where the 2.85 and 2.93 were calculated by rounding `lower_bound` and `upper_bound` to two decimal places. \n",
    "\n",
    "**Note:** For the returned string, make sure you follow the format above and remember to change the course name and the confidence interval for different courses. For the histogram, the label on the x-axis should also change accordingly to the courses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ci_and_hist(course_name):\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2_3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#: try it out\n",
    "ci_and_hist('WCWP')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.4.** Your friend claims that Marshall's writing course DOC is actually not as hard as everyone says. She says that because our CAPE data is only a sample of the full population of course offerings, the actual average grade for DOC could be 3.3. Run the cell below to use the `ci_and_hist` function you defined above to calculate an approximate 95% confidence interval for the average grade in DOC. Can you reject her hypothesis using this confidence interval? Assign your answer to variable `q2_4`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Yes, the confidence interval includes 3.3\n",
    "2. No, the confidence interval includes 3.3\n",
    "3. Yes, the confidence interval doesn't include 3.3\n",
    "4. No, the confidence interval doesn't include 3.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ci_and_hist(\"DOC\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q2_4 = ...\n",
    "q2_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2_4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.5a.** Now that you've looked at the average grades for different courses, you're curious about the average amount of time each writing course requires. This time, you'll test whether each individual course has the same average study hours per week as that of all the writing courses combined. \n",
    "\n",
    "First, produce 1,000 bootstrapped estimates for the average study hours per week of all the writing courses combined. Use these estimates to produce an approximate 99% confidence interval for the true average study hours. Round the bounds of the confidence interval to 2 decimal places and save them into `study_lower_bound` and `study_upper_bound`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study_lower_bound = ...\n",
    "study_lower_bound\n",
    "\n",
    "study_upper_bound = ...\n",
    "study_upper_bound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2_5a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.5b.** Compare the average study hours for each individual writing course to the average study hours of all writing courses combined. Your final answer should be a 5 element array named `study_hypotheses`.\n",
    "\n",
    "In the order of `[CAT, DOC, HUM, MMW, WCWP]`, the corresponding element in the array `study_hypotheses` should be -1 if the course's average study hours is significantly lower than that of all the writing courses combined, 0 if you cannot reject the hypothesis that the course has the same average study hours as that of all the courses combined, and 1 if the course's average study hours is significantly higher than that of all the courses combined. You may want to use the `course_means_fixed` table you created in Question 1b.\n",
    "\n",
    "**Note:** It's okay to hard code your answer for this question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study_hypotheses = ...\n",
    "study_hypotheses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2_5b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Testing the Central Limit Theorem\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Central Limit Theorem tells us that the probability distribution of the sum or average of a large random sample drawn with replacement will be roughly normal, *regardless of the distribution of the population from which the sample is drawn*.\n",
    "\n",
    "That's a pretty big claim, but the theorem doesn't stop there. It further states that the standard deviation of this normal distribution is given by $$\\frac{\\text{sd of the original distribution}}{\\sqrt{\\text{sample size}}}$$ In other words, suppose we start with *any distribution* that has standard deviation $\\sigma$, take a sample of size $n$ (where $n$ is a large number) from that distribution with replacement, and compute the mean of that sample. If we repeat this procedure many times, then those sample means will have a normal distribution with standard deviation $\\frac{\\sigma}{\\sqrt{n}}$.\n",
    "\n",
    "That's an even bigger claim than the first one! The proof of the theorem is beyond the scope of this class, but in this exercise, we will be exploring some data to see the CLT in action."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.1.** The CLT only applies when sample sizes are \"sufficiently large.\" This isn't a very precise statement. Is 10 large?  How about 50?  The truth is that it depends both on the original population distribution and just how \"normal\" you want the result to look. Let's use a simulation to get a feel for how the distribution of the sample mean changes as sample size goes up.\n",
    "\n",
    "Consider a coin flip. If we say `Heads` is $1$ and `Tails` is $0$, then there's a 50% chance of getting a 1 and a 50% chance of getting a 0, which is definitely not a normal distribution.  The average of several coin tosses is equal to the proportion of heads in those coin tosses, so the CLT should apply if we compute the sample proportion of heads many times.\n",
    "\n",
    "Write a function called `simulate_sample_n` that takes in a sample size $n$. It should return an array that contains 5000 sample proportions of heads, each from $n$ coin flips."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_sample_n(n):\n",
    "    ...\n",
    "simulate_sample_n(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3_1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"hide\">\\pagebreak</div>\n",
    "The code below will use the function you just defined to plot the empirical distribution of the sample mean for several different sample sizes. The x- and y-scales are kept the same to facilitate comparisons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#: run this cell to visualize\n",
    "bins = np.arange(-0.01,1.05,0.02)\n",
    "\n",
    "for sample_size in np.array([2, 5, 10, 20, 50, 100, 200, 400]):\n",
    "    bpd.DataFrame().assign(**{'Sample_Size:{}'.format(sample_size) : simulate_sample_n(sample_size)}).plot(kind = 'hist', bins=bins)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that even the means of samples of 10 items follow a roughly bell-shaped distribution.  A sample of 50 items looks quite bell-shaped."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"hide\">\\pagebreak</div>\n",
    "Now we will test the second claim of the CLT: That the SD of the sample mean is the SD of the original distribution, divided by the square root of the sample size.\n",
    "\n",
    "We have imported flight delay data and computed the standard deviation  of delay time (in minutes):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#: run this cell, but don't change it under penalty of law!\n",
    "united = bpd.read_csv('data/united_summer2015.csv')\n",
    "united_std = np.std(united.get('Delay'))\n",
    "united_std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.2.** Write a function called `predict_sd`.  It takes a sample size `n` (a number) as its argument.  It returns the predicted standard deviation of the sample mean for samples of size `n` from the flight delays, according to the CLT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sd(n):\n",
    "    ...\n",
    "\n",
    "predict_sd(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3_2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.3.** Write a function called `empirical_sd` that takes a sample size `n` as its argument. The function should simulate 1000 samples of size `n` from the flight delays dataset, and it should return the standard deviation of the **means of those 1000 samples**.\n",
    "\n",
    "*Hint:* This function will be similar to the `simulate_sample_n` function you wrote earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def empirical_sd(n): \n",
    "    ...\n",
    "empirical_sd(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3_3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below will plot the predicted and empirical SDs for the delay data for various sample sizes. It may take a few moments to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#: run this cell to visualize\n",
    "sd_table = bpd.DataFrame().assign(Sample_Size = np.arange(1, 101, 10))\n",
    "predicted = sd_table.get('Sample_Size').apply(predict_sd)\n",
    "empirical = sd_table.get('Sample_Size').apply(empirical_sd)\n",
    "sd_table = sd_table.assign(Predicted_SD = predicted, Empirical_SD = empirical)\n",
    "sd_table.plot(kind='scatter',x='Sample_Size', y='Empirical_SD',label = 'Empirical_SD')\n",
    "sd_table.plot(kind='scatter',x='Sample_Size', y='Predicted_SD',label = 'Predicted_SD')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. UCSD P/NP Decision and the Normal Distribution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because of the pandemic, UCSD had a decision to make last quarter on whether or not students should be allowed to take their courses for a Pass/No Pass instead of a grade. Before coming to a conclusion, a Data Scientist at UCSD decided to see if students actually wanted a P/NP option, or if it was just a vocal minority asking for these accomodations.\n",
    "\n",
    "He polled a uniform random sample of all UCSD students, and he found that 300 of the 500 sampled students are in favor of a P/NP grading option."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#: run this cell, but don't change it!\n",
    "sample = bpd.DataFrame().assign(\n",
    "    Vote =np.array([\"Yes\", \"No\"]),\n",
    "    Count= np.array([300,   200]))\n",
    "sample_size = sample.get(\"Count\").sum()\n",
    "sample_proportions = sample.assign(\n",
    "    Proportion=sample.get(\"Count\") / sample_size)\n",
    "sample_proportions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "He used 1,000 bootstrap resamples to compute a confidence interval for the proportion of all UCSD students who are in favor of P/NP.  Run the next cell to see the empirical distribution of Yes proportions in the 1,000 resamples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#: run this cell, but don't change it!\n",
    "resample_yes_proportions = np.array([])\n",
    "for i in np.arange(1000):\n",
    "    resample = np.random.multinomial(sample_size,sample_proportions.get(\"Proportion\"))/sample_size\n",
    "    resample_yes_proportions = np.append(resample_yes_proportions, resample[0])\n",
    "bpd.DataFrame().assign(Resample_Yes_proportion = resample_yes_proportions).plot(kind = 'hist',bins=np.arange(.2, .8, .01))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"hide\">\\pagebreak</div>\n",
    "In a population whose members are 0 and 1, there is a simple formula for the standard deviation of that population:\n",
    "\n",
    "$$\\text{standard deviation} = \\sqrt{(\\text{proportion of 0s}) \\times (\\text{proportion of 1s})}$$\n",
    "\n",
    "(Figuring out this formula, starting from the definition of the standard deviation, is a fun exercise for those who enjoy algebra -- and who doesn't?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4.1.**\n",
    "**Without accessing the data in `resample_yes_proportions` in any way**, and instead using only the Central Limit Theorem and the numbers of \"For\" and \"Against\" students in our sample of 500, compute a number `approximate_sd` that's the predicted standard deviation of the array `resample_yes_proportions` according to the Central Limit Theorem. Since you don't know the true proportions of 0s and 1s in the population, use the proportions in the sample instead (since they're probably similar)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "approximate_sd = ...\n",
    "approximate_sd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4_1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4.2.**\n",
    "Compute the standard deviation of the array `resample_yes_proportions` to verify that your answer to question 2 is approximately right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exact_sd = ...\n",
    "exact_sd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4_2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4.3.**\n",
    "**Still without accessing `resample_yes_proportions` in any way**, compute an approximate 95% confidence interval for the proportion of Yes voters in California.  The cell below draws your interval as a red bar below the histogram of `resample_yes_proportions`; use that to verify that your answer looks right.\n",
    "\n",
    "*Hint*: Before, we've used `percentile` on the bootstrap distribution to find the bounds for the confidence interval. Now, we're not allowed to use the bootstrap distribution -- but we don't need it! We know (from the Central Limit Theorem) that the distribution of the sample mean is Normal with a certain standard deviation. We also know that 95% of the area of the normal distribution falls within a certain number of standard deviations from the mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_proportions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_limit = ...\n",
    "upper_limit = ...\n",
    "\n",
    "lower_limit, upper_limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4_3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#: print the confidence interval\n",
    "print('lower:', lower_limit, 'upper:', upper_limit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#: run this cell to plot your confidence interval\n",
    "bpd.DataFrame().assign(Resample_Yes_proportion = resample_yes_proportions).plot(bins=np.arange(.2, .8, .01),kind = 'hist').plot(np.array([lower_limit, upper_limit]), np.array([0,0]), c='r', lw=10);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your confidence interval should be near the number 0.55.  That means we can't be very sure if students want P/NP, even though the sample \"For\" proportion is a bit above 0.5.\n",
    "\n",
    "UCSD really needs to know if students need this option or not. To have more confidence in the result of the poll, the decide to redo it with a larger sample. They'd be happy if the standard deviation of the sample mean were only 0.005.  They ask their Data Scientist to run a new poll with a sample size that's large enough to achieve that. (Polling is time-consuming, so the sample also shouldn't be bigger than necessary.)\n",
    "\n",
    "Instead of making the conservative assumption that the population standard deviation is 0.5 (coding \"For\" voters as 1 and \"Against\" voters as 0), he decides to assume that it's equal to the standard deviation of the sample,\n",
    "\n",
    "$$\\sqrt{(\\text{\"For\" proportion in the sample}) \\times (\\text{\"Against\" proportion in the sample})}.$$\n",
    "\n",
    "Under that assumption, he computes the smallest sample size necessary in order to be confident that the standard deviation of the sample mean is only 0.005."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4.4.**\n",
    "What sample size did he find? Assign your answer to the variable `sample_size`. Remember the sample size needs to be an integer.\n",
    "\n",
    "Remember that: $$\\text{sample means SD} = \\frac{\\text{population SD}}{\\sqrt{\\text{sample size}}},$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma = ...\n",
    "sample_size = ...\n",
    "sample_size = ...\n",
    "sample_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4_4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Quick Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 5.1.** Referring back to the previous question about P/NP, suppose UCSD wanted to be even more precise and would be happier if the sample standard deviation of the sample mean was 0.001. Can the Data Scientist carry this out?\n",
    "1. Yes, he needs to sample more people so that the sample means SD becomes smaller\n",
    "2. Yes, he can repeat the sample again until he comes across a sample with a standard deviation of 0.001\n",
    "3. No, there is no need to be more precise and 0.005 is acceptable as it is.\n",
    "4. No, the sample size required to reach that sample standard deviation is too large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q5_1 = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q5_1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 5.2.** What is the correct way of standardizing a value of 35 if the mean is 45 and the standard deviation is 10?\n",
    "\n",
    "1.\n",
    "$$\\frac{({45-35})^2}{10}$$\n",
    "\n",
    "2.\n",
    "$$\\frac{45-35}{10}$$\n",
    "\n",
    "3.\n",
    "$$\\frac{35-45}{10}$$\n",
    "\n",
    "4.\n",
    "$$\\frac{{35-45}}{\\sqrt{10}}$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q5_2 = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q5_2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 5.3.** According to Chebychev's Bounds, within how many SDs does at least 65% of the data fall in?\n",
    "\n",
    "1. 1.34\n",
    "2. 1.69\n",
    "3. 2.04\n",
    "4. 2.50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q5_3 = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q5_3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 5.4.** Can we sample from any distribution and apply Central Limit Theorem?\n",
    "\n",
    "1. Yes\n",
    "2. No"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q5_4 = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q5_4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finish Line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations! You are done with homework 7.\n",
    "\n",
    "To submit your assignment:\n",
    "\n",
    "1. Select `Kernel -> Restart & Run All` to ensure that you have executed all cells, including the test cells.\n",
    "2. Read through the notebook to make sure everything is fine and all tests passed.\n",
    "3. Run the cell below to run all tests, and make sure that they all pass.\n",
    "4. Download your notebook using `File -> Download as -> Notebook (.ipynb)`, then upload your notebook to Gradescope."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grader.check_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
